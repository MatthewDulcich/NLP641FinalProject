{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coreml implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# Load the CoreML model\n",
    "model = ct.models.MLModel('converted_model.mlpackage')\n",
    "\n",
    "# Prepare input data (replace 'input_image.jpg' with your test image)\n",
    "image = Image.open('cat.jpeg').resize((224, 224))\n",
    "image = np.array(image) / 127.0 - 1.0\n",
    "input_data = {'input_image': image}\n",
    "\n",
    "# Perform inference and measure time\n",
    "start_time = time.time()\n",
    "output = model.predict(input_data)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "# Print inference result\n",
    "print(\"Inference result:\", output)\n",
    "\n",
    "# Print inference time\n",
    "print(\"Inference time:\", inference_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested with TensorFlow 2.6.2\n",
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "\n",
    "tf_keras_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pass in `tf.keras.Model` to the Unified Conversion API\n",
    "mlmodel = ct.convert(tf_keras_model, convert_to=\"mlprogram\", source=\"tensorflow\")\n",
    "\n",
    "# or save the keras model in SavedModel directory format and then convert\n",
    "tf_keras_model.save('tf_keras_model')\n",
    "mlmodel = ct.convert('tf_keras_model', convert_to=\"mlprogram\")\n",
    "\n",
    "# or load the model from a SavedModel and then convert\n",
    "tf_keras_model = tf.keras.models.load_model('tf_keras_model')\n",
    "mlmodel = ct.convert(tf_keras_model, convert_to=\"mlprogram\")\n",
    "\n",
    "# or save the keras model in HDF5 format and then convert\n",
    "tf_keras_model.save('tf_keras_model.h5')\n",
    "mlmodel = ct.convert('tf_keras_model.h5', convert_to=\"mlprogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install coremltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "saved_model_path = 'saved_model/'\n",
    "tf.saved_model.save(cnn_model, saved_model_path)\n",
    "\n",
    "# Convert the TensorFlow SavedModel to CoreML\n",
    "model = ct.convert(saved_model_path)\n",
    "\n",
    "model.save('converted_model.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.constant([[1, 2, 0], [3, 0, 0], [4, 5, 6]])\n",
    "tf.math.not_equal(inputs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
