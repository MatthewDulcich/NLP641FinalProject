{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import make_dataset, custom_standardization, reduce_dataset_dim, valid_test_split\n",
    "from settings import *\n",
    "from custom_schedule import custom_schedule\n",
    "from model import get_cnn_model, TransformerEncoderBlock, TransformerDecoderBlock, ImageCaptioningModel\n",
    "from utility import save_tokenizer\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import numpy as np\n",
    "import wandb\n",
    "from keras.callbacks import LambdaCallback\n",
    "from datetime import datetime\n",
    "from tensorflow.python.profiler import profiler_v2\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge\n",
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'apikey.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 33\u001b[0m\n\u001b[0;32m     18\u001b[0m wandb_callback \u001b[38;5;241m=\u001b[39m LambdaCallback(\n\u001b[0;32m     19\u001b[0m     on_batch_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m batch, logs: wandb\u001b[38;5;241m.\u001b[39mlog({\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_train_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: logs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     })\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Read the API key from the file\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapikey.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     34\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Login to wandb\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'apikey.txt'"
     ]
    }
   ],
   "source": [
    "from dataset import make_dataset, custom_standardization, reduce_dataset_dim, valid_test_split\n",
    "from settings import *\n",
    "from custom_schedule import custom_schedule\n",
    "from model import get_cnn_model, TransformerEncoderBlock, TransformerDecoderBlock, ImageCaptioningModel\n",
    "from utility import save_tokenizer\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import numpy as np\n",
    "import wandb\n",
    "from keras.callbacks import LambdaCallback\n",
    "from datetime import datetime\n",
    "from tensorflow.python.profiler import profiler_v2\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "# Define the callback\n",
    "wandb_callback = LambdaCallback(\n",
    "    on_batch_end=lambda batch, logs: wandb.log({\n",
    "        'batch_train_loss': logs['loss'],\n",
    "        'batch_train_accuracy': logs['acc']\n",
    "    }),\n",
    "    on_epoch_end=lambda epoch, logs: wandb.log({\n",
    "        'epoch_train_loss': logs['loss'],\n",
    "        # 'epoch_train_accuracy': logs['acc'],\n",
    "        'epoch_valid_loss': logs.get('val_loss', None),\n",
    "        'epoch_valid_accuracy': logs.get('val_acc', None)\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "# Read the API key from the file\n",
    "with open('apikey.txt', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Login to wandb\n",
    "wandb.login(key=api_key)\n",
    "\n",
    "# Start a new run\n",
    "run = wandb.init(project='image-labeling-project', entity='dulcich')\n",
    "\n",
    "\n",
    "print('tensorflow version: ', tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Load dataset\n",
    "with open(train_data_json_path) as json_file:\n",
    "    train_data = json.load(json_file)\n",
    "with open(valid_data_json_path) as json_file:\n",
    "    valid_data = json.load(json_file)\n",
    "with open(text_data_json_path) as json_file:\n",
    "    text_data = json.load(json_file)\n",
    "\n",
    "# For reduce number of images in the dataset\n",
    "if REDUCE_DATASET:\n",
    "    train_data, valid_data = reduce_dataset_dim(train_data, valid_data)\n",
    "print(\"Number of training samples: \", len(train_data))\n",
    "print(\"Number of validation samples: \", len(valid_data))\n",
    "\n",
    "# Log the number of training and validation samples\n",
    "wandb.log({'Number of training samples': len(train_data), 'Number of validation samples': len(valid_data)})\n",
    "\n",
    "# Define tokenizer of Text Dataset\n",
    "tokenizer = TextVectorization(\n",
    "    max_tokens=MAX_VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQ_LENGTH,\n",
    "    standardize=custom_standardization,\n",
    "    ngrams=1\n",
    ")\n",
    "\n",
    "# Adapt tokenizer to Text Dataset\n",
    "tokenizer.adapt(text_data)\n",
    "\n",
    "# Define vocabulary size of Dataset\n",
    "VOCAB_SIZE = len(tokenizer.get_vocabulary())\n",
    "#print(VOCAB_SIZE)\n",
    "\n",
    "# 20k images for validation set and 13432 images for test set\n",
    "valid_data, test_data  = valid_test_split(valid_data)\n",
    "print(\"Number of validation samples after splitting with test set: \", len(valid_data))\n",
    "print(\"Number of test samples: \", len(test_data))\n",
    "\n",
    "# Setting batch dataset\n",
    "train_dataset = make_dataset(list(train_data.keys()), list(train_data.values()), data_aug=TRAIN_SET_AUG, tokenizer=tokenizer)\n",
    "valid_dataset = make_dataset(list(valid_data.keys()), list(valid_data.values()), data_aug=VALID_SET_AUG, tokenizer=tokenizer)\n",
    "if TEST_SET:\n",
    "    test_dataset = make_dataset(list(test_data.keys()), list(test_data.values()), data_aug=False, tokenizer=tokenizer)\n",
    "\n",
    "# Define Model\n",
    "cnn_model = get_cnn_model()\n",
    "\n",
    "encoder = TransformerEncoderBlock(\n",
    "    embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=NUM_HEADS\n",
    ")\n",
    "encoder2 = TransformerEncoderBlock(\n",
    "    embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=NUM_HEADS\n",
    ")\n",
    "decoder = TransformerDecoderBlock(\n",
    "    embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=NUM_HEADS, vocab_size=VOCAB_SIZE\n",
    ")\n",
    "caption_model = ImageCaptioningModel(\n",
    "    cnn_model=cnn_model, encoder=encoder, encoder2=encoder2, decoder=decoder\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "cross_entropy = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")\n",
    "\n",
    "# EarlyStopping criteria\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "# Create a learning rate schedule\n",
    "lr_scheduler = custom_schedule(EMBED_DIM)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler, beta_1=0.9, beta_2=0.98, epsilon=1e-9) # Changed to tf.keras.optimizers.Adam from keras.optimizers.Adam\n",
    "\n",
    "# Compile the model\n",
    "caption_model.compile(optimizer=optimizer, loss=cross_entropy, metrics=[\"accuracy\"])\n",
    "# caption_model.compile(optimizer=optimizer, loss=cross_entropy, metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history = caption_model.fit(train_dataset,\n",
    "                            epochs=EPOCHS,\n",
    "                            validation_data=valid_dataset,\n",
    "                            callbacks=[early_stopping, wandb_callback])\n",
    "\n",
    "# Compute definitive metrics on train/valid set\n",
    "train_metrics = caption_model.evaluate(train_dataset, batch_size=BATCH_SIZE)\n",
    "valid_metrics = caption_model.evaluate(valid_dataset, batch_size=BATCH_SIZE)\n",
    "wandb.log({'Train Loss': train_metrics[0], 'Train Accuracy': train_metrics[1],\n",
    "           'Valid Loss': valid_metrics[0], 'Valid Accuracy': valid_metrics[1]})\n",
    "\n",
    "\n",
    "\n",
    "if TEST_SET:\n",
    "    test_metrics = caption_model.evaluate(test_dataset, batch_size=BATCH_SIZE)\n",
    "    wandb.log({'Test Loss': test_metrics[0], 'Test Accuracy': test_metrics[1]})\n",
    "\n",
    "\n",
    "print(\"Train Loss = %.4f - Train Accuracy = %.4f\" % (train_metrics[0], train_metrics[1]))\n",
    "print(\"Valid Loss = %.4f - Valid Accuracy = %.4f\" % (valid_metrics[0], valid_metrics[1]))\n",
    "if TEST_SET:\n",
    "    print(\"Test Loss = %.4f - Test Accuracy = %.4f\" % (test_metrics[0], test_metrics[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for batch_data in valid_dataset:\n",
    "    output = ImageCaptioningModel.test_step(batch_data)\n",
    "    results.append(output)\n",
    "\n",
    "# Now, results contain all the predictions and true captions\n",
    "predicted_captions = [item['predicted_captions'] for item in results]\n",
    "true_captions = [item['true_captions'] for item in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_captions(predicted_captions, true_captions):\n",
    "    bleu_scores = []\n",
    "    rouge = Rouge()\n",
    "    meteor_scores = []\n",
    "\n",
    "    for pred, true in zip(predicted_captions, true_captions):\n",
    "        # Compute BLEU score\n",
    "        reference = [true.split()]  # BLEU expects a list of references\n",
    "        candidate = pred.split()\n",
    "        bleu_scores.append(sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "        # Compute ROUGE score\n",
    "        scores = rouge.get_scores(pred, true)\n",
    "        rouge_scores.append(scores[0]['rouge-l']['f'])  # Example: F1-score of ROUGE-L\n",
    "\n",
    "        # Compute METEOR score\n",
    "        meteor_scores.append(meteor_score([true], pred))\n",
    "\n",
    "    # Compute average scores\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    avg_rouge = sum(rouge_scores) / len(rouge_scores)\n",
    "    avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "    return {\"avg_bleu\": avg_bleu, \"avg_rouge\": avg_rouge, \"avg_meteor\": avg_meteor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def evaluate_captions(predicted_captions, true_captions):\n",
    "    bleu_scores = []\n",
    "    rouge = Rouge()\n",
    "    meteor_scores = []\n",
    "\n",
    "    for pred, true in zip(predicted_captions, true_captions):\n",
    "        # Compute BLEU score\n",
    "        reference = [true.split()]  # BLEU expects a list of references\n",
    "        candidate = pred.split()\n",
    "        bleu_scores.append(sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "        # Compute ROUGE score\n",
    "        scores = rouge.get_scores(pred, true)\n",
    "        rouge_scores.append(scores[0]['rouge-l']['f'])  # Example: F1-score of ROUGE-L\n",
    "\n",
    "        # Compute METEOR score\n",
    "        meteor_scores.append(meteor_score([true], pred))\n",
    "\n",
    "    # Compute average scores\n",
    "    avg_bleu = sum(bleu_scores)\n",
    "    avg_rouge = sum(rouge_scores)\n",
    "    avg_meteor = sum(meteor_scores)\n",
    "\n",
    "    return {\"avg_bleu\": avg_bleu, \"avg_rouge\": avg_rouge, \"avg_meteor\": avg_meteor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
