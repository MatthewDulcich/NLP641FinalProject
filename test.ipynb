{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 20:23:01.888037: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-04-29 20:23:01.888058: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-04-29 20:23:01.888063: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-04-29 20:23:01.888384: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-29 20:23:01.888401: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7, 7, 1280)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "# Load the base model\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Preprocess the image\n",
    "image_path = 'dog.jpeg'\n",
    "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n",
    "img_tensor = tf.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Pass the image tensor through the model\n",
    "cnn_model = tf.keras.Model(inputs=base_model.input, outputs=base_model.output)\n",
    "output = cnn_model(img_tensor)\n",
    "\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Set Metal as the default compute device\n",
    "# tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "\n",
    "# Load ResNet50 without top layers\n",
    "resnet50 = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',  # Or specify None if you don't want to use pre-trained weights\n",
    "    input_shape=(224, 224, 3)  # Adjust input shape according to your needs\n",
    ")\n",
    "resnet50.trainable = False  # Freeze the weights of the ResNet50 base model\n",
    "\n",
    "# Define additional layers\n",
    "output = resnet50.output\n",
    "output = tf.keras.layers.Reshape((-1, 2048))(output)  # Reshape the output to match the desired shape\n",
    "output = tf.keras.layers.Dense(1280)(output)  # Add a dense layer to reduce dimensionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "(1, 49, 1280)\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "cnn_model = tf.keras.Model(inputs=resnet50.input, outputs=output)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = 'dog.jpeg'\n",
    "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.keras.applications.resnet50.preprocess_input(img_array)  # Preprocess input for ResNet50\n",
    "\n",
    "# Process the image through the model\n",
    "features = cnn_model.predict(tf.expand_dims(img_array, axis=0))\n",
    "\n",
    "print(features.shape)  # Check the shape of the extracted features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coreml implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute '_get_save_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m      5\u001b[0m tf_keras_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      6\u001b[0m     [\n\u001b[1;32m      7\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     ]\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Pass in `tf.keras.Model` to the Unified Conversion API\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m mlmodel \u001b[38;5;241m=\u001b[39m \u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_keras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlprogram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtensorflow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# or save the keras model in SavedModel directory format and then convert\u001b[39;00m\n\u001b[1;32m     17\u001b[0m tf_keras_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_keras_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/coremltools/converters/_converters_entry.py:574\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, compute_precision, skip_model_load, compute_units, package_dir, debug, pass_pipeline)\u001b[0m\n\u001b[1;32m    566\u001b[0m     specification_version \u001b[38;5;241m=\u001b[39m _set_default_specification_version(exact_target)\n\u001b[1;32m    568\u001b[0m use_default_fp16_io \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    569\u001b[0m     specification_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m specification_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m AvailableTarget\u001b[38;5;241m.\u001b[39miOS16\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m need_fp16_cast_pass\n\u001b[1;32m    572\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m mlmodel \u001b[38;5;241m=\u001b[39m \u001b[43mmil_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs_as_tensor_or_image_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# None or list[ct.ImageType/ct.TensorType]\u001b[39;49;00m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_model_load\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_model_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackage_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackage_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecification_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecification_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmain_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_default_fp16_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_default_fp16_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exact_target \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlprogram\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mlmodel\u001b[38;5;241m.\u001b[39m_input_has_infinite_upper_bound():\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor mlprogram, inputs with infinite upper_bound is not allowed. Please set upper_bound\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    593\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to a positive value in \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRangeDim()\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m param in ct.convert().\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    594\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/coremltools/converters/mil/converter.py:188\u001b[0m, in \u001b[0;36mmil_convert\u001b[0;34m(model, convert_from, convert_to, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;129m@_profile\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmil_convert\u001b[39m(\n\u001b[1;32m    151\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    156\u001b[0m ):\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    Convert model from a specified frontend `convert_from` to a specified\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    converter backend `convert_to`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m        See `coremltools.converters.convert`\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_mil_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_from\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConverterRegistry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/coremltools/converters/mil/converter.py:212\u001b[0m, in \u001b[0;36m_mil_convert\u001b[0;34m(model, convert_from, convert_to, registry, modelClass, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     weights_dir \u001b[38;5;241m=\u001b[39m _tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory()\n\u001b[1;32m    210\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m weights_dir\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m--> 212\u001b[0m proto, mil_program \u001b[38;5;241m=\u001b[39m \u001b[43mmil_convert_to_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mconvert_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                     \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m _reset_conversion_state()\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmilinternal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/coremltools/converters/mil/converter.py:286\u001b[0m, in \u001b[0;36mmil_convert_to_proto\u001b[0;34m(model, convert_from, convert_to, converter_registry, main_pipeline, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m frontend_pipeline, backend_pipeline \u001b[38;5;241m=\u001b[39m _construct_other_pipelines(\n\u001b[1;32m    282\u001b[0m     main_pipeline, convert_from, convert_to\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m frontend_converter \u001b[38;5;241m=\u001b[39m frontend_converter_type()\n\u001b[0;32m--> 286\u001b[0m prog \u001b[38;5;241m=\u001b[39m \u001b[43mfrontend_converter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m PassPipelineManager\u001b[38;5;241m.\u001b[39mapply_pipeline(prog, frontend_pipeline)\n\u001b[1;32m    289\u001b[0m PassPipelineManager\u001b[38;5;241m.\u001b[39mapply_pipeline(prog, main_pipeline)\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/coremltools/converters/mil/converter.py:98\u001b[0m, in \u001b[0;36mTensorFlow2Frontend.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrontend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TF2Loader\n\u001b[1;32m     97\u001b[0m tf2_loader \u001b[38;5;241m=\u001b[39m TF2Loader(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf2_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/coremltools/converters/mil/frontend/tensorflow/load.py:61\u001b[0m, in \u001b[0;36mTFLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     60\u001b[0m output_names \u001b[38;5;241m=\u001b[39m get_output_names(outputs)\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_def_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_def \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_def\u001b[38;5;241m.\u001b[39mnode) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     64\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Graph should have at least 1 node, Got empty graph.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/coremltools/converters/mil/frontend/tensorflow2/load.py:132\u001b[0m, in \u001b[0;36mTF2Loader._graph_def_from_model\u001b[0;34m(self, output_names)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_graph_def_from_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Overwrites TFLoader._graph_def_from_model()\"\"\"\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     cfs, graph_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_functions_and_graph_def\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, _tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;66;03m# For the keras model, check if the outputs is provided by the user.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;66;03m# If not, we make sure the coreml model outputs order is the same as\u001b[39;00m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;66;03m# the original keras model\u001b[39;00m\n\u001b[1;32m    137\u001b[0m         cf \u001b[38;5;241m=\u001b[39m cfs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/coremltools/converters/mil/frontend/tensorflow2/load.py:103\u001b[0m, in \u001b[0;36mTF2Loader._get_concrete_functions_and_graph_def\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m     cfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, _tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel):\n\u001b[0;32m--> 103\u001b[0m     cfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_fn_from_tf_keras\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, _tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mGraphDef):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/coremltools/converters/mil/frontend/tensorflow2/load.py:315\u001b[0m, in \u001b[0;36mTF2Loader._concrete_fn_from_tf_keras\u001b[0;34m(keras_model)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_concrete_fn_from_tf_keras\u001b[39m(keras_model: _tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel):\n\u001b[0;32m--> 315\u001b[0m     input_signature \u001b[38;5;241m=\u001b[39m \u001b[43m_saving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_input_signature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_original_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     fn \u001b[38;5;241m=\u001b[39m _saving_utils\u001b[38;5;241m.\u001b[39mtrace_model_call(keras_model, input_signature)\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [fn\u001b[38;5;241m.\u001b[39mget_concrete_function()]\n",
      "File \u001b[0;32m~/anaconda3/envs/ML-AI/lib/python3.11/site-packages/tensorflow/python/keras/saving/saving_utils.py:74\u001b[0m, in \u001b[0;36mmodel_input_signature\u001b[0;34m(model, keep_original_batch_size)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_input_signature\u001b[39m(model, keep_original_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Inspect model to get its input signature.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m  The model's input signature is a list with a single (possibly-nested) object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    TensorSpecs. This list does not contain the `training` argument.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m   input_specs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_save_spec\u001b[49m(dynamic_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m keep_original_batch_size)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     75\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m input_specs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_get_save_spec'"
     ]
    }
   ],
   "source": [
    "# Tested with TensorFlow 2.6.2\n",
    "import tensorflow as tf\n",
    "import coremltools as ct\n",
    "\n",
    "tf_keras_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pass in `tf.keras.Model` to the Unified Conversion API\n",
    "mlmodel = ct.convert(tf_keras_model, convert_to=\"mlprogram\", source=\"tensorflow\")\n",
    "\n",
    "# or save the keras model in SavedModel directory format and then convert\n",
    "tf_keras_model.save('tf_keras_model')\n",
    "mlmodel = ct.convert('tf_keras_model', convert_to=\"mlprogram\")\n",
    "\n",
    "# or load the model from a SavedModel and then convert\n",
    "tf_keras_model = tf.keras.models.load_model('tf_keras_model')\n",
    "mlmodel = ct.convert(tf_keras_model, convert_to=\"mlprogram\")\n",
    "\n",
    "# or save the keras model in HDF5 format and then convert\n",
    "tf_keras_model.save('tf_keras_model.h5')\n",
    "mlmodel = ct.convert('tf_keras_model.h5', convert_to=\"mlprogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 12:00:01.976131: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-05-07 12:00:01.976156: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-05-07 12:00:01.976160: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-05-07 12:00:01.977595: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-07 12:00:01.977626: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=bool, numpy=\n",
       "array([[ True,  True, False],\n",
       "       [ True, False, False],\n",
       "       [ True,  True,  True]])>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.constant([[1, 2, 0], [3, 0, 0], [4, 5, 6]])\n",
    "tf.math.not_equal(inputs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
